{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les noms des colonnes pour le CSV\n",
    "avis_columns = [\"id_avis\", \"id_restaurant\", \"id_utilisateur\", \"note_restaurant\", \"date_avis\", \"contenu_avis\", \"ratio_avis\"]\n",
    "restaurant_columns = [\"id_restaurant\", \"nom\", \"localisation\", \"categorie\", \"tags\", \"note_globale\"]\n",
    "utilisateur_columns = [\"id_utilisateur\", \"nom\", \"ratio_avis_global\"]\n",
    "\n",
    "# Fichiers CSV\n",
    "avis_csv = \"avis.csv\"\n",
    "restaurant_csv = \"restaurant.csv\"\n",
    "utilisateur_csv = \"utilisateur.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser les fichiers CSV avec les colonnes\n",
    "def init_csv_file(filename, columns):\n",
    "    with open(filename, mode=\"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=columns)\n",
    "        writer.writeheader()\n",
    "\n",
    "# Appeler cette fonction pour chaque fichier\n",
    "init_csv_file(avis_csv, avis_columns)\n",
    "init_csv_file(restaurant_csv, restaurant_columns)\n",
    "init_csv_file(utilisateur_csv, utilisateur_columns)\n",
    "\n",
    "# Fonction pour gérer les erreurs HTTP et les retries\n",
    "def request_with_retry(url, headers, max_retries=3):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            return response\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(f\"Erreur HTTP: {e}\")\n",
    "            retries += 1\n",
    "            time.sleep(random.uniform(2, 5))  # Attendre avant de réessayer\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Erreur de requête: {e}\")\n",
    "            break\n",
    "    return None  # Si la requête échoue après plusieurs tentatives\n",
    "\n",
    "# Ajouter un User-Agent pour simuler un navigateur\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.5993.89 Safari/537.36\",\n",
    "    \"Accept-Language\": \"fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "}\n",
    "\n",
    "# Scraper les données pour un restaurant donné\n",
    "def scrape_restaurant(url, restaurant_id):\n",
    "    try:\n",
    "        # Effectuer une requête avec gestion des erreurs et retries\n",
    "        response = request_with_retry(url, HEADERS)\n",
    "        if response is None:\n",
    "            print(f\"Échec de récupération de la page {url}. Passer à la suivante.\")\n",
    "            return\n",
    "\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Extraction des informations du restaurant (assurez-vous d'utiliser les bonnes classes HTML)\n",
    "        nom = soup.find(\"h1\", class_=\"\").text.strip() if soup.find(\"h1\", class_=\"\") else \"Nom non trouvé\"\n",
    "        localisation = soup.find(\"span\", class_=\"\").text.strip() if soup.find(\"span\", class_=\"\") else \"Localisation non trouvée\"\n",
    "        categorie = \"Brasserie\"  # Remplir avec des catégories fixes ou dynamiques\n",
    "        tags = \"Cuisine Française, Ambiance décontractée\"  # Exemple de tags, à extraire dynamiquement si possible\n",
    "        note_globale = float(soup.find(\"span\", class_=\"\").text.strip().replace(\",\", \".\")) if soup.find(\"span\", class_=\"\") else 0.0\n",
    "\n",
    "        # Enregistrer les informations dans le fichier restaurant.csv\n",
    "        with open(restaurant_csv, mode=\"a\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=restaurant_columns)\n",
    "            writer.writerow({\n",
    "                \"id_restaurant\": restaurant_id,\n",
    "                \"nom\": nom,\n",
    "                \"localisation\": localisation,\n",
    "                \"categorie\": categorie,\n",
    "                \"tags\": tags,\n",
    "                \"note_globale\": note_globale,\n",
    "            })\n",
    "\n",
    "        # Scraper les avis\n",
    "        avis_divs = soup.find_all(\"div\", class_=\"\")  # Classe des avis (à ajuster)\n",
    "        for avis_id, avis_div in enumerate(avis_divs, start=1):\n",
    "            contenu_avis = avis_div.find(\"q\", class_=\"\").text.strip() if avis_div.find(\"q\", class_=\"\") else \"Contenu non trouvé\"\n",
    "            note_restaurant = float(avis_div.find(\"span\", class_=\"\").text.strip()) if avis_div.find(\"span\", class_=\"\") else 0.0\n",
    "            date_avis = datetime.strptime(avis_div.find(\"span\", class_=\"\").text.strip(), \"%d %B %Y\") if avis_div.find(\"span\", class_=\"\") else datetime.now()\n",
    "            ratio_avis = note_restaurant / 5.0  # Exemple de ratio calculé\n",
    "\n",
    "            # Enregistrer les avis dans le fichier avis.csv\n",
    "            with open(avis_csv, mode=\"a\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "                writer = csv.DictWriter(file, fieldnames=avis_columns)\n",
    "                writer.writerow({\n",
    "                    \"id_avis\": avis_id,\n",
    "                    \"id_restaurant\": restaurant_id,\n",
    "                    \"id_utilisateur\": avis_id,  # À remplacer par un vrai ID utilisateur si disponible\n",
    "                    \"note_restaurant\": note_restaurant,\n",
    "                    \"date_avis\": date_avis.strftime(\"%Y-%m-%d\"),\n",
    "                    \"contenu_avis\": contenu_avis,\n",
    "                    \"ratio_avis\": ratio_avis,\n",
    "                })\n",
    "\n",
    "        # Simuler des utilisateurs\n",
    "        with open(utilisateur_csv, mode=\"a\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=utilisateur_columns)\n",
    "            writer.writerow({\n",
    "                \"id_utilisateur\": avis_id,\n",
    "                \"nom\": f\"Utilisateur {avis_id}\",\n",
    "                \"ratio_avis_global\": ratio_avis,\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du scraping du restaurant {url} : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur lors du scraping du restaurant https://www.tripadvisor.fr/Restaurant_Review-g187265-d695217-Reviews-Brasserie_Georges-Lyon_Rhone_Auvergne_Rhone_Alpes.html : could not convert string to float: 'DécouvrirVoyagesAvisEURSe connecterLyonHôtelsActivitésRestaurantsVolsLocations de vacancesCroisièresVoitures de locationForums'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Exemple : URL du restaurant Brasserie Georges\n",
    "base_url = \"https://www.tripadvisor.fr/Restaurant_Review-g187265-d695217-Reviews-Brasserie_Georges-Lyon_Rhone_Auvergne_Rhone_Alpes.html\"\n",
    "\n",
    "# Scraper plusieurs restaurants (ajouter leurs URLs et IDs dans une liste)\n",
    "restaurants_to_scrape = [\n",
    "    {\"url\": base_url, \"id\": 1},\n",
    "    # Ajouter d'autres restaurants ici...\n",
    "]\n",
    "\n",
    "# Lancer le scraping\n",
    "for restaurant in restaurants_to_scrape:\n",
    "    scrape_restaurant(restaurant[\"url\"], restaurant[\"id\"])\n",
    "    time.sleep(2)  # Pause entre les requêtes pour éviter d'être bloqué\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envnlpprojet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
